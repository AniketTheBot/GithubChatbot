Talk to Your Codebase ğŸ¤–ğŸ’¬

A cinematic, full-stack RAG (Retrieval-Augmented Generation) application that allows you to chat with any GitHub repository.
It features a Firefly landing page, glassmorphic chat interface, and deep context awareness with source citations.

âœ¨ Features

ğŸ† Cinematic Landing Page â€” Firefly motion, parallax, typewriter.

ğŸ“¥ Smart Ingestion â€” Clones + parses + chunks code (Python, JS, TS, Rust, Goâ€¦)

ğŸ§  RAG Pipeline â€” OpenAI Embeddings + Supabase pgvector.

ğŸ’¬ Context-Aware Chat â€” Maintains conversation memory.

ğŸ“Œ Citations â€” Shows which files were used.

ğŸ§© Syntax Highlighting â€” Dracula-themed code blocks.

ğŸ”„ Session Management â€” â€œNew Repoâ€ clears DB + state instantly.

ğŸ›  Tech Stack
Frontend

React (Vite)

Tailwind CSS

Framer Motion

Lucide Icons

Backend

FastAPI

LangChain

GitPython

Database

Supabase (PostgreSQL + pgvector)

AI

OpenAI GPT-4o-mini

Text-Embedding-3-Small

ğŸš€ Getting Started
âœ… Prerequisites

Node.js & npm

Python 3.10+

Supabase Account

OpenAI API Key

1. Database Setup (Supabase)

Go to Supabase Dashboard â†’ SQL Editor
Paste and run:

-- Enable pgvector
create extension if not exists vector;

-- Documents table
create table documents (
  id uuid primary key default gen_random_uuid(),
  content text,
  metadata jsonb,
  embedding vector(1536)
);

-- Search function
create function match_documents (
  query_embedding vector(1536),
  match_threshold float,
  match_count int
)
returns table (
  id uuid,
  content text,
  metadata jsonb,
  similarity float
)
language plpgsql
as $$
begin
  return query
  select
    documents.id,
    documents.content,
    documents.metadata,
    1 - (documents.embedding <=> query_embedding) as similarity
  from documents
  where 1 - (documents.embedding <=> query_embedding) > match_threshold
  order by documents.embedding <=> query_embedding
  limit match_count;
end;
$$;

2. Backend Setup
cd backend

Create virtual environment
# Windows
python -m venv venv
.\venv\Scripts\activate

# Mac/Linux
python3 -m venv venv
source venv/bin/activate

Install dependencies
pip install -r requirements.txt

Environment variables

Create backend/.env:

OPENAI_API_KEY=sk-proj-...
SUPABASE_URL=https://your-project-id.supabase.co
SUPABASE_KEY=ey...

Run FastAPI server
uvicorn app.main:app --reload --port 8003


Backend is live at:

http://127.0.0.1:8003

3. Frontend Setup
cd frontend
npm install

Ensure API URL is correct

In src/App.tsx:

const API_URL = "http://127.0.0.1:8003";

Run Vite dev server
npm run dev


Your frontend runs at:

http://localhost:5173

ğŸ® How to Use

Open the app.

Paste a GitHub URL (e.g., https://github.com/jwasham/practice-python)

Click Ingest

Wait while:

Cloning

Chunking

Embedding

Storing

Start chatting:

"How does the authentication work?"
"Show me the binary search function."
"Rewrite this in Rust."


Click New to reset.

ğŸ“‚ Project Structure
root/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ github.py        # Clone repos
â”‚   â”‚   â”‚   â”œâ”€â”€ loader.py        # Read + detect file types
â”‚   â”‚   â”‚   â”œâ”€â”€ chunker.py       # Split intelligently
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_store.py  # Supabase + pgvector
â”‚   â”‚   â”‚   â””â”€â”€ llm.py           # OpenAI calls
â”‚   â”‚   â””â”€â”€ main.py              # FastAPI endpoints
â”‚   â”œâ”€â”€ temp_repos/
â”‚   â”œâ”€â”€ .env
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â”œâ”€â”€ LandingPage.tsx
â”‚   â”‚   â”œâ”€â”€ ChatBot.tsx
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â””â”€â”€ package.json

âš ï¸ Troubleshooting
âŒ "Invalid URL"

Use https://github.com/...

âŒ 500 Internal Server Error

Check backend .env

âŒ CORS Errors

Backend must run on port 8003.

ğŸ“œ License

Open-source. Modify & distribute freely.